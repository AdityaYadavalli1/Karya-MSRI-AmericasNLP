Could not read wav
Could not read bribri000494.wav
Could not read wav
Could not read bribri000744.wav
Downloading and preparing dataset csv/default to /home/t-hdiddee/.cache/huggingface/datasets/csv/default-7c00c6e9b4543c4a/0.0.0/652c3096f041ee27b04d2232d41f10547a8fecda3e284a79a0ec4053c916ef7a...
Dataset csv downloaded and prepared to /home/t-hdiddee/.cache/huggingface/datasets/csv/default-7c00c6e9b4543c4a/0.0.0/652c3096f041ee27b04d2232d41f10547a8fecda3e284a79a0ec4053c916ef7a. Subsequent calls will reuse this data.
49
{'a': 1, 'b': 2, 'c': 3, 'd': 4, 'e': 5, 'g': 6, 'h': 7, 'i': 8, 'j': 9, 'k': 10, 'l': 11, 'm': 12, 'n': 13, 'o': 14, 'p': 15, 'q': 16, 'r': 17, 's': 18, 't': 19, 'u': 20, 'v': 21, 'w': 22, 'y': 23, 'z': 24, 'à': 25, 'á': 26, 'â': 27, 'è': 28, 'é': 29, 'ê': 30, 'ë': 31, 'ì': 32, 'í': 33, 'î': 34, 'ñ': 35, 'ò': 36, 'ó': 37, 'ô': 38, 'ö': 39, 'ù': 40, 'ú': 41, 'û': 42, '̀': 43, '́': 44, '̂': 45, '̠': 46, '|': 0, '[UNK]': 47, '[PAD]': 48, '<s>': 49, '</s>': 50}
51
51
Using custom data configuration default-7c00c6e9b4543c4a
Downloading data files: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00, 7861.86it/s]
Extracting data files: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00, 1938.22it/s]
0 tables [00:00, ? tables/s]/home/t-hdiddee/venv/asr/lib/python3.8/site-packages/datasets/download/streaming_download_manager.py:697: FutureWarning: the 'mangle_dupe_cols' keyword is deprecated and will be removed in a future version. Please take steps to stop the use of 'mangle_dupe_cols'
  return pd.read_csv(xopen(filepath_or_buffer, "rb", use_auth_token=use_auth_token), **kwargs)
0 tables [00:00, ? tables/s]/home/t-hdiddee/venv/asr/lib/python3.8/site-packages/datasets/download/streaming_download_manager.py:697: FutureWarning: the 'mangle_dupe_cols' keyword is deprecated and will be removed in a future version. Please take steps to stop the use of 'mangle_dupe_cols'
  return pd.read_csv(xopen(filepath_or_buffer, "rb", use_auth_token=use_auth_token), **kwargs)
100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00, 1132.07it/s]
100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 495/495 [00:00<00:00, 23271.91ex/s]
100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 250/250 [00:00<00:00, 23620.30ex/s]
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 496.07ba/s]
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 759.56ba/s]
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
  0%|                                                                                                                                     | 0/495 [00:00<?, ?ex/s]/home/t-hdiddee/venv/asr/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:154: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.
  warnings.warn(
100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 495/495 [00:00<00:00, 1057.82ex/s]
100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 250/250 [00:00<00:00, 1263.51ex/s]
Some weights of the model checkpoint at facebook/wav2vec2-xls-r-300m were not used when initializing Wav2Vec2ForCTC: ['quantizer.codevectors', 'project_q.bias', 'quantizer.weight_proj.bias', 'project_q.weight', 'quantizer.weight_proj.weight', 'project_hid.weight', 'project_hid.bias']
- This IS expected if you are initializing Wav2Vec2ForCTC from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing Wav2Vec2ForCTC from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of Wav2Vec2ForCTC were not initialized from the model checkpoint at facebook/wav2vec2-xls-r-300m and are newly initialized: ['lm_head.weight', 'lm_head.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
/home/t-hdiddee/venv/asr/lib/python3.8/site-packages/transformers/models/wav2vec2/modeling_wav2vec2.py:1618: FutureWarning: The method `freeze_feature_extractor` is deprecated and will be removed in Transformers v5.Please use the equivalent `freeze_feature_encoder` method instead.
  warnings.warn(
Using cuda_amp half precision backend
The following columns in the training set don't have a corresponding argument in `Wav2Vec2ForCTC.forward` and have been ignored: input_length. If input_length are not expected by `Wav2Vec2ForCTC.forward`,  you can safely ignore this message.
/home/t-hdiddee/venv/asr/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 495
  Num Epochs = 80
  Instantaneous batch size per device = 16
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 2
  Total optimization steps = 1200
Automatic Weights & Biases logging enabled, to disable set os.environ["WANDB_DISABLED"] = "true"
  0%|▏                                                                                                                           | 2/1200 [00:04<39:32,  1.98s/it]/home/t-hdiddee/venv/asr/lib/python3.8/site-packages/transformers/trainer.py:1808: FutureWarning: Non-finite norm encountered in torch.nn.utils.clip_grad_norm_; continuing anyway. Note that the default behavior will change in a future release to error out if a non-finite total norm is encountered. At that point, setting error_if_nonfinite=false will be required to retain the old behavior.
  nn.utils.clip_grad_norm_(


























  4%|█████                                                                                                                      | 49/1200 [01:10<29:29,  1.54s/it]
  4%|█████▏                                                                                                                     | 50/1200 [01:11<25:21,  1.32s/it]The following columns in the evaluation set don't have a corresponding argument in `Wav2Vec2ForCTC.forward` and have been ignored: input_length. If input_length are not expected by `Wav2Vec2ForCTC.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 250
  Batch size = 8

  File "asr_baseline.py", line 227, in <module>███████████████████████████████████████████████████████████████████████████████    | 31/32 [00:05<00:00,  6.05it/s]
    trainer.train()
  File "/home/t-hdiddee/venv/asr/lib/python3.8/site-packages/transformers/trainer.py", line 1521, in train
    return inner_training_loop(
  File "/home/t-hdiddee/venv/asr/lib/python3.8/site-packages/transformers/trainer.py", line 1840, in _inner_training_loop
    self._maybe_log_save_evaluate(tr_loss, model, trial, epoch, ignore_keys_for_eval)
  File "/home/t-hdiddee/venv/asr/lib/python3.8/site-packages/transformers/trainer.py", line 2065, in _maybe_log_save_evaluate
    metrics = self.evaluate(ignore_keys=ignore_keys_for_eval)
  File "/home/t-hdiddee/venv/asr/lib/python3.8/site-packages/transformers/trainer.py", line 2787, in evaluate
    output = eval_loop(
  File "/home/t-hdiddee/venv/asr/lib/python3.8/site-packages/transformers/trainer.py", line 3072, in evaluation_loop
    metrics = self.compute_metrics(EvalPrediction(predictions=all_preds, label_ids=all_labels))
  File "asr_baseline.py", line 102, in compute_metrics
    print(pred_logits.size())
TypeError: 'int' object is not callable