Could not read wav
Could not read bribri000494.wav
Could not read wav
Could not read bribri000744.wav
Downloading and preparing dataset csv/default to /home/t-hdiddee/.cache/huggingface/datasets/csv/default-9a341ec41283841f/0.0.0/652c3096f041ee27b04d2232d41f10547a8fecda3e284a79a0ec4053c916ef7a...
Dataset csv downloaded and prepared to /home/t-hdiddee/.cache/huggingface/datasets/csv/default-9a341ec41283841f/0.0.0/652c3096f041ee27b04d2232d41f10547a8fecda3e284a79a0ec4053c916ef7a. Subsequent calls will reuse this data.
49
{'a': 1, 'b': 2, 'c': 3, 'd': 4, 'e': 5, 'g': 6, 'h': 7, 'i': 8, 'j': 9, 'k': 10, 'l': 11, 'm': 12, 'n': 13, 'o': 14, 'p': 15, 'q': 16, 'r': 17, 's': 18, 't': 19, 'u': 20, 'v': 21, 'w': 22, 'y': 23, 'z': 24, 'à': 25, 'á': 26, 'â': 27, 'è': 28, 'é': 29, 'ê': 30, 'ë': 31, 'ì': 32, 'í': 33, 'î': 34, 'ñ': 35, 'ò': 36, 'ó': 37, 'ô': 38, 'ö': 39, 'ù': 40, 'ú': 41, 'û': 42, '̀': 43, '́': 44, '̂': 45, '̠': 46, '|': 0, '[UNK]': 47, '[PAD]': 48, '<s>': 49, '</s>': 50}
51
51
Using custom data configuration default-9a341ec41283841f
Downloading data files: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00, 8371.86it/s]
Extracting data files: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00, 2017.95it/s]
0 tables [00:00, ? tables/s]/home/t-hdiddee/venv/asr/lib/python3.8/site-packages/datasets/download/streaming_download_manager.py:697: FutureWarning: the 'mangle_dupe_cols' keyword is deprecated and will be removed in a future version. Please take steps to stop the use of 'mangle_dupe_cols'
  return pd.read_csv(xopen(filepath_or_buffer, "rb", use_auth_token=use_auth_token), **kwargs)
0 tables [00:00, ? tables/s]/home/t-hdiddee/venv/asr/lib/python3.8/site-packages/datasets/download/streaming_download_manager.py:697: FutureWarning: the 'mangle_dupe_cols' keyword is deprecated and will be removed in a future version. Please take steps to stop the use of 'mangle_dupe_cols'
  return pd.read_csv(xopen(filepath_or_buffer, "rb", use_auth_token=use_auth_token), **kwargs)
100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00, 1169.96it/s]
100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 495/495 [00:00<00:00, 23429.22ex/s]
100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 250/250 [00:00<00:00, 23605.94ex/s]
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 494.49ba/s]
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 727.04ba/s]
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
  0%|                                                                                                                                     | 0/495 [00:00<?, ?ex/s]/home/t-hdiddee/venv/asr/lib/python3.8/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:154: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.
  warnings.warn(
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 495/495 [00:00<00:00, 986.28ex/s]
100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 250/250 [00:00<00:00, 1323.48ex/s]
Some weights of the model checkpoint at facebook/wav2vec2-xls-r-300m were not used when initializing Wav2Vec2ForCTC: ['project_hid.bias', 'project_q.weight', 'quantizer.weight_proj.bias', 'quantizer.weight_proj.weight', 'quantizer.codevectors', 'project_hid.weight', 'project_q.bias']
- This IS expected if you are initializing Wav2Vec2ForCTC from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing Wav2Vec2ForCTC from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of Wav2Vec2ForCTC were not initialized from the model checkpoint at facebook/wav2vec2-xls-r-300m and are newly initialized: ['lm_head.bias', 'lm_head.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
/home/t-hdiddee/venv/asr/lib/python3.8/site-packages/transformers/models/wav2vec2/modeling_wav2vec2.py:1618: FutureWarning: The method `freeze_feature_extractor` is deprecated and will be removed in Transformers v5.Please use the equivalent `freeze_feature_encoder` method instead.
  warnings.warn(
Using cuda_amp half precision backend
The following columns in the training set don't have a corresponding argument in `Wav2Vec2ForCTC.forward` and have been ignored: input_length. If input_length are not expected by `Wav2Vec2ForCTC.forward`,  you can safely ignore this message.
/home/t-hdiddee/venv/asr/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 495
  Num Epochs = 80
  Instantaneous batch size per device = 16
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 2
  Total optimization steps = 1200
Automatic Weights & Biases logging enabled, to disable set os.environ["WANDB_DISABLED"] = "true"
  0%|                                                                                                                                    | 0/1200 [00:00<?, ?it/s]/home/t-hdiddee/venv/asr/lib/python3.8/site-packages/transformers/trainer.py:1808: FutureWarning: Non-finite norm encountered in torch.nn.utils.clip_grad_norm_; continuing anyway. Note that the default behavior will change in a future release to error out if a non-finite total norm is encountered. At that point, setting error_if_nonfinite=false will be required to retain the old behavior.
  nn.utils.clip_grad_norm_(
  0%|▌                                                                                                                           | 5/1200 [00:08<28:36,  1.44s/it]The following columns in the evaluation set don't have a corresponding argument in `Wav2Vec2ForCTC.forward` and have been ignored: input_length. If input_length are not expected by `Wav2Vec2ForCTC.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 250
  Batch size = 8


 88%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████▍               | 28/32 [00:04<00:00,  5.66it/s]
9575250
(250, 751, 51)

 97%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████    | 31/32 [00:04<00:00,  6.57it/s]

Configuration saved in ../test/Bribri/best_cer_model/config.json██████████████████████████████████████████████████████████████    | 31/32 [00:04<00:00,  6.57it/s]
Model weights saved in ../test/Bribri/best_cer_model/pytorch_model.bin
Feature extractor saved in ../test/Bribri/best_cer_model/preprocessor_config.json
  0%|▌                                                                                                                           | 5/1200 [00:30<28:36,  1.44s/it]
0.972630033557047
0.972630033557047



  1%|█                                                                                                                        | 10/1200 [00:37<1:06:10,  3.34s/it]The following columns in the evaluation set don't have a corresponding argument in `Wav2Vec2ForCTC.forward` and have been ignored: input_length. If input_length are not expected by `Wav2Vec2ForCTC.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 250
  Batch size = 8


 94%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏       | 30/32 [00:04<00:00,  6.25it/s]
9575250
(250, 751, 51)

 97%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████    | 31/32 [00:04<00:00,  6.24it/s]

Configuration saved in ../test/Bribri/best_cer_model/config.json██████████████████████████████████████████████████████████████    | 31/32 [00:04<00:00,  6.24it/s]
0.9671770134228188
0.9671770134228188
{'eval_loss': 11.59540843963623, 'eval_wer': 1.0, 'eval_cer': 0.9671770134228188, 'eval_runtime': 23.9872, 'eval_samples_per_second': 10.422, 'eval_steps_per_second': 1.334, 'epoch': 0.65}
Model weights saved in ../test/Bribri/best_cer_model/pytorch_model.bin
Feature extractor saved in ../test/Bribri/best_cer_model/preprocessor_config.json


  1%|█▌                                                                                                                       | 15/1200 [01:07<1:00:48,  3.08s/it]The following columns in the evaluation set don't have a corresponding argument in `Wav2Vec2ForCTC.forward` and have been ignored: input_length. If input_length are not expected by `Wav2Vec2ForCTC.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 250
  Batch size = 8

 72%|█████████████████████████████████████████████████████████████████████████████████████████▊                                   | 23/32 [00:03<00:02,  3.88it/s]
9575250
(250, 751, 51)

 97%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████    | 31/32 [00:04<00:00,  6.75it/s]
0.9797609060402684
0.9671770134228188



  2%|██                                                                                                                         | 20/1200 [01:23<44:59,  2.29s/it]The following columns in the evaluation set don't have a corresponding argument in `Wav2Vec2ForCTC.forward` and have been ignored: input_length. If input_length are not expected by `Wav2Vec2ForCTC.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 250
  Batch size = 8


 97%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████    | 31/32 [00:04<00:00,  6.80it/s]
9575250
(250, 751, 51)
38301
0.9993708053691275
0.9671770134228188



  2%|██▌                                                                                                                        | 25/1200 [01:38<42:58,  2.19s/it]The following columns in the evaluation set don't have a corresponding argument in `Wav2Vec2ForCTC.forward` and have been ignored: input_length. If input_length are not expected by `Wav2Vec2ForCTC.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 250
  Batch size = 8


 94%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏       | 30/32 [00:04<00:00,  6.31it/s]
9575250
(250, 751, 51)

 97%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████    | 31/32 [00:04<00:00,  6.76it/s]
1.0
0.9671770134228188

  2%|███                                                                                                                        | 30/1200 [01:50<32:22,  1.66s/it]The following columns in the evaluation set don't have a corresponding argument in `Wav2Vec2ForCTC.forward` and have been ignored: input_length. If input_length are not expected by `Wav2Vec2ForCTC.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 250
  Batch size = 8


 84%|█████████████████████████████████████████████████████████████████████████████████████████████████████████▍                   | 27/32 [00:04<00:01,  4.84it/s]
9575250
(250, 751, 51)

 97%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████    | 31/32 [00:04<00:00,  6.71it/s]
1.0
0.9671770134228188




  3%|███▌                                                                                                                       | 35/1200 [02:07<43:30,  2.24s/it]The following columns in the evaluation set don't have a corresponding argument in `Wav2Vec2ForCTC.forward` and have been ignored: input_length. If input_length are not expected by `Wav2Vec2ForCTC.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 250
  Batch size = 8


 97%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████    | 31/32 [00:04<00:00,  6.77it/s]
9575250
(250, 751, 51)
38301
1.0
0.9671770134228188



  3%|████                                                                                                                       | 40/1200 [02:21<41:12,  2.13s/it]The following columns in the evaluation set don't have a corresponding argument in `Wav2Vec2ForCTC.forward` and have been ignored: input_length. If input_length are not expected by `Wav2Vec2ForCTC.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 250
  Batch size = 8


 97%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████    | 31/32 [00:04<00:00,  6.35it/s]
9575250
(250, 751, 51)
38301
1.0
0.9671770134228188

  4%|████▌                                                                                                                      | 45/1200 [02:34<33:10,  1.72s/it]The following columns in the evaluation set don't have a corresponding argument in `Wav2Vec2ForCTC.forward` and have been ignored: input_length. If input_length are not expected by `Wav2Vec2ForCTC.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 250
  Batch size = 8


 84%|█████████████████████████████████████████████████████████████████████████████████████████████████████████▍                   | 27/32 [00:04<00:01,  4.90it/s]
9575250
(250, 751, 51)

 97%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████    | 31/32 [00:04<00:00,  6.52it/s]
1.0
0.9671770134228188



  4%|████▉                                                                                                                      | 48/1200 [02:47<49:08,  2.56s/it]
  4%|█████▏                                                                                                                     | 50/1200 [02:50<37:31,  1.96s/it]The following columns in the evaluation set don't have a corresponding argument in `Wav2Vec2ForCTC.forward` and have been ignored: input_length. If input_length are not expected by `Wav2Vec2ForCTC.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 250
  Batch size = 8


 94%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏       | 30/32 [00:04<00:00,  5.91it/s]
9575250
(250, 751, 51)

 97%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████    | 31/32 [00:04<00:00,  6.43it/s]
1.0
0.9671770134228188


  5%|█████▋                                                                                                                     | 55/1200 [03:05<41:52,  2.19s/it]The following columns in the evaluation set don't have a corresponding argument in `Wav2Vec2ForCTC.forward` and have been ignored: input_length. If input_length are not expected by `Wav2Vec2ForCTC.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 250
  Batch size = 8

 72%|█████████████████████████████████████████████████████████████████████████████████████████▊                                   | 23/32 [00:03<00:02,  3.78it/s]
9575250
(250, 751, 51)


 97%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████    | 31/32 [00:04<00:00,  6.53it/s]
1.0
0.9671770134228188


  5%|██████▏                                                                                                                    | 60/1200 [03:17<32:08,  1.69s/it]The following columns in the evaluation set don't have a corresponding argument in `Wav2Vec2ForCTC.forward` and have been ignored: input_length. If input_length are not expected by `Wav2Vec2ForCTC.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 250
  Batch size = 8


 97%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████    | 31/32 [00:04<00:00,  6.63it/s]
9575250
(250, 751, 51)
38301
1.0
0.9671770134228188



  5%|██████▋                                                                                                                    | 65/1200 [03:35<42:10,  2.23s/it]The following columns in the evaluation set don't have a corresponding argument in `Wav2Vec2ForCTC.forward` and have been ignored: input_length. If input_length are not expected by `Wav2Vec2ForCTC.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 250
  Batch size = 8

 75%|█████████████████████████████████████████████████████████████████████████████████████████████▊                               | 24/32 [00:03<00:01,  4.18it/s]
9575250
(250, 751, 51)


 97%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████    | 31/32 [00:04<00:00,  6.44it/s]
1.0
0.9671770134228188


  6%|███████▏                                                                                                                   | 70/1200 [03:49<41:46,  2.22s/it]The following columns in the evaluation set don't have a corresponding argument in `Wav2Vec2ForCTC.forward` and have been ignored: input_length. If input_length are not expected by `Wav2Vec2ForCTC.forward`,  you can safely ignore this message.
***** Running Evaluation *****
  Num examples = 250
  Batch size = 8
 69%|█████████████████████████████████████████████████████████████████████████████████████▉                                       | 22/32 [00:03<00:01,  5.09it/s]
 69%|█████████████████████████████████████████████████████████████████████████████████████▉                                       | 22/32 [00:03<00:01,  5.09it/s]
9575250
(250, 751, 51)
 97%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████    | 31/32 [00:04<00:00,  6.84it/s]

 97%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████    | 31/32 [00:04<00:00,  6.84it/s]
1.0
0.9671770134228188


  6%|███████▋                                                                                                                   | 75/1200 [04:02<31:09,  1.66s/it]The following columns in the evaluation set don't have a corresponding argument in `Wav2Vec2ForCTC.forward` and have been ignored: input_length. If input_length are not expected by `Wav2Vec2ForCTC.forward`,  you can safely ignore this message.
 25%|███████████████████████████████▌                                                                                              | 8/32 [00:00<00:02,  8.10it/s]
  Num examples = 250
  Batch size = 8
 25%|███████████████████████████████▌                                                                                              | 8/32 [00:00<00:02,  8.10it/s]
 25%|███████████████████████████████▌                                                                                              | 8/32 [00:00<00:02,  8.10it/s]
 66%|██████████████████████████████████████████████████████████████████████████████████                                           | 21/32 [00:02<00:02,  5.00it/s]
 97%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████    | 31/32 [00:04<00:00,  6.86it/s]
 97%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████    | 31/32 [00:04<00:00,  6.86it/s]
9575250
(250, 751, 51)
38301
1.0
0.9671770134228188

  6%|███████▉                                                                                                                   | 78/1200 [04:14<48:09,  2.58s/it]Traceback (most recent call last):
  File "/home/t-hdiddee/venv/asr/lib/python3.8/site-packages/datasets/formatting/formatting.py", line 281, in __call__oop
    trainer.train()
  File "/home/t-hdiddee/venv/asr/lib/python3.8/site-packages/transformers/trainer.py", line 1521, in train
    return inner_training_loop(
  File "/home/t-hdiddee/venv/asr/lib/python3.8/site-packages/datasets/formatting/formatting.py", line 281, in __call__oop
    for step, inputs in enumerate(epoch_iterator):
  File "/home/t-hdiddee/venv/asr/lib/python3.8/site-packages/torch/utils/data/dataloader.py", line 521, in __next__
    data = self._next_data()
  File "/home/t-hdiddee/venv/asr/lib/python3.8/site-packages/datasets/formatting/formatting.py", line 281, in __call__oop
    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration
  File "/home/t-hdiddee/venv/asr/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py", line 44, in fetch
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/home/t-hdiddee/venv/asr/lib/python3.8/site-packages/datasets/formatting/formatting.py", line 281, in __call__oop
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/home/t-hdiddee/venv/asr/lib/python3.8/site-packages/datasets/arrow_dataset.py", line 2227, in __getitem__
    return self._getitem(
  File "/home/t-hdiddee/venv/asr/lib/python3.8/site-packages/datasets/formatting/formatting.py", line 281, in __call__oop
    formatted_output = format_table(
  File "/home/t-hdiddee/venv/asr/lib/python3.8/site-packages/datasets/formatting/formatting.py", line 532, in format_table
    return formatter(pa_table, query_type=query_type)
  File "/home/t-hdiddee/venv/asr/lib/python3.8/site-packages/datasets/formatting/formatting.py", line 281, in __call__oop
    return self.format_row(pa_table)
  File "/home/t-hdiddee/venv/asr/lib/python3.8/site-packages/datasets/formatting/formatting.py", line 310, in format_row
    row = self.python_arrow_extractor().extract_row(pa_table)
  File "/home/t-hdiddee/venv/asr/lib/python3.8/site-packages/datasets/formatting/formatting.py", line 140, in extract_row
    return _unnest(pa_table.to_pydict())
KeyboardInterrupt